{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4bc96e3",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e371e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT : main_var \n",
      "IMPORT : utils_art\n",
      "IMPORT : text_analysis\n",
      "WARNING:tensorflow:From C:\\Users\\User\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT : embedding_keyword_module_lib\n",
      "IMPORT : article_scraping_lib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORT : article_parsing_lib\n",
      "IMPORT : openai_module_lib\n"
     ]
    }
   ],
   "source": [
    "import main_var\n",
    "env = \"test_new/\"\n",
    "mv = main_var.main_var(env=env)\n",
    "\n",
    "from article_scraping_lib import *\n",
    "from article_parsing_lib import *\n",
    "from openai_module_lib import *\n",
    "from embedding_keyword_module_lib import *\n",
    "from utils_art import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf7c17",
   "metadata": {},
   "source": [
    "## Querring and saving artilce list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ff60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loop_scraping(8,'2010-01-01','2024-01-01',sampling_1=12,sampling_2=3,save_steps=True,save_final=True,display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35572c10",
   "metadata": {},
   "source": [
    "#### Display Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6bce882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = openDFcsv(mv.query_path,\"query_fileF\")\n",
    "plotDFstatisticsQuerry(df,70,True)\n",
    "displayStats(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311179fc",
   "metadata": {},
   "source": [
    "#### Filter articles with a source that is too/not enought scrapped and source/category/date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cafd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = filterQuerryDataset(df,400,30,True,False,True)\n",
    "plotDFstatisticsQuerry(df2)\n",
    "displayStats(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3499a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "categroy_l = [\"WORLD\",\"NATION\",\"BUSINESS\",\"TECHNOLOGY\"]\n",
    "categroy_l = []\n",
    "# source_l = [\"The New York Times\",\"The Nation\",\"Business Insider\",\"Business Insider\"]\n",
    "source_l = [\"Newsweek\",\"Yahoo Finance\",\"ESPN\",\"Fox News\"]\n",
    "source_l = [\"World Health Organization (WHO)\",\"Pew Research Center\",\"The New York Times\",\"Nature.com\",\"Tax Foundation\",\"Union of Concerned Scientists\"]\n",
    "df3 = selectOnDf(df2,date_start=\"2010-01-01\", date_end=\"2024-01-01\", categroy_list=categroy_l, source_list=source_l)\n",
    "displayStats(df3)\n",
    "saveDFcsv(df3,mv.query_path,\"query_fileG_cap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce570e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readArticleFileTable(index_from=0,index_to=11064,save_articles=True,save_final=True,save_steps=True,display_df=True,step_pct=0.01,add_nlp=2,filtered_input_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930f8309",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = joinQuerryAndParse(save=True,remove_invalid=True,display=True,filtered_input_df=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9359d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = mainGeneration(True,False,10,9642,7500,9999,True,True,True,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73e0f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_mat = extractEmbeddingFromFile(999999999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd497e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = openDFcsv(mv.join1_path,mv.join1_filename)\n",
    "# genrateKeywordExtract(df, 9641,500,\"keywords_list\")\n",
    "df = mainKhttp://localhost:8888/notebooks/OneDrive/Desktop/Article_LLM/main_codebase/MAIN_CODE.ipynb#eywordWF(9641,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60ef3b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61741c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainJoin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db8524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = [\"category\",\"source_title\",\"year_month\",\"url_TLD\",\"year\"]\n",
    "df_list_len = calculateStatsColList(df,col_list,\"len\",display_df=True)\n",
    "df_list_npl = calculateStatsColList(df,col_list,\"nlp\",display_df=True,display_stats=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d81540d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb78803",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainJoin()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3b404e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERRY dataset loaded from  C:/Users/User/OneDrive/Desktop/Article_LLM/main_files/1_1_query_main/test_new/\n",
      "QUERRY dataset has entry length of : 11520 \n",
      "\n",
      "PARSSING dataset loaded from  C:/Users/User/OneDrive/Desktop/Article_LLM/main_files/1_2_scarp_main/test_new/\n",
      "PARSSING dataset has entry length of : 11520  (100.0% of querry data)\n",
      "\n",
      "JOINED dataset has entry length of : 11262  (97.76% of parssing data)\n",
      "JOINED dataset VALID entries : 10125  (89.9% of joined data)\n",
      "JOINED dataset INVALID entries : 1137  (-10.1% of joined data)\n",
      "\n",
      "TOTAL yield : from 11520  to  10125 (87.89% yeald)\n",
      "\n",
      "JOINED dataset saved here : C:/Users/User/OneDrive/Desktop/Article_LLM/main_files/1_4_join_main/test_new/join1_file.csv\n"
     ]
    }
   ],
   "source": [
    "# df = openDFcsv(mv.query_path,mv.query_filename)\n",
    "# df3 = selectOnDf(df2,\"\",\"\")\n",
    "# plotDFstatisticsQuerry(df,70)\n",
    "# displayStats(df)\n",
    "# saveDFcsv(df3,mv.query_path,mv.query_filename)\n",
    "\n",
    "\n",
    "\n",
    "# df = loop_scraping(9,'1999-03-27','2024-03-19',sampling_1=5,sampling_2=5,save_steps=True,save_final=True,display=True)\n",
    "# plotDFstatisticsQuerry(df,70)\n",
    "# displayStats(df)\n",
    "\n",
    "# df = openDFcsv(mv.query_path,mv.query_filename)\n",
    "# df2 =  filterQuerryDataset(df,150,10,True,True,True)\n",
    "# plotDFstatisticsQuerry(df2,70,True)\n",
    "# displayStats(df2)\n",
    "\n",
    "# df = openDFcsv(mv.query_path,mv.query_filename)\n",
    "# df_querry = readArticleFileTable(index_from=0,index_to=99999999999,save_articles=True,save_final=True,save_steps=True,display_df=True,step_pct=0.005,add_nlp=2,filtered_input_df=True)\n",
    "# df_join = joinQuerryAndParse(save=True,remove_invalid=True,display=True,filtered_input_df=True)# df_embd = mainGeneration(True,False,100,99999999,7500,9999,True,True,True,0.005)\n",
    "# emb_mat = extractEmbeddingFromFile(9999999999)\n",
    "# df_key = mainKeywordWF(99999999999999,1000)\n",
    "# df_final = mainJoinOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17793f7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = openDFcsv(mv.query_path,mv.query_filename)\n",
    "# df3 = selectOnDf(df2,\"\",\"\")\n",
    "# plotDFstatisticsQuerry(df,70)\n",
    "# displayStats(df)\n",
    "# saveDFcsv(df3,mv.query_path,mv.query_filename)\n",
    "\n",
    "\n",
    "max_num = 10000000\n",
    "step_pct=0.005\n",
    "df = loop_scraping(9,'2000-01-01','2024-01-01',sampling_1=5,sampling_2=5,save_steps=True,save_final=True,display=True)\n",
    "df2 =  filterQuerryDataset(df,150,10,True,True,True)\n",
    "df_querry = readArticleFileTable(index_from=0,index_to=max_num,save_articles=True,save_final=True,save_steps=True,display_df=True,step_pct=step_pct,add_nlp=2,filtered_input_df=True)\n",
    "df_join = joinQuerryAndParse(save=True,remove_invalid=True,display=True,filtered_input_df=True)\n",
    "df_embd = mainGeneration(True,False,10,max_num,7500,1000,True,True,True,step_pct)\n",
    "emb_mat = extractEmbeddingFromFile(max_num)\n",
    "df_key = mainKeywordWF(max_num,100)\n",
    "df_final = mainJoinOut()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e22c19e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title_q           object\n",
      "link              object\n",
      "published         object\n",
      "source_url        object\n",
      "source_title      object\n",
      "category          object\n",
      "year               int64\n",
      "year_month        object\n",
      "pk                object\n",
      "url_list          object\n",
      "url_TLD           object\n",
      "url               object\n",
      "pk_p              object\n",
      "title_p           object\n",
      "authors           object\n",
      "publish_date     float64\n",
      "keywords_list     object\n",
      "text_len         float64\n",
      "valid               bool\n",
      "tb.sent          float64\n",
      "tb.noun          float64\n",
      "tb.word          float64\n",
      "tb.char          float64\n",
      "tb.pol           float64\n",
      "tb.sub           float64\n",
      "tb.polaj         float64\n",
      "tb.pos           float64\n",
      "tb.neg           float64\n",
      "vs.pos           float64\n",
      "vs.neu           float64\n",
      "vs.neg           float64\n",
      "vs.comp          float64\n",
      "ts.pos           float64\n",
      "ts.neg           float64\n",
      "nlp_error        float64\n",
      "al.pos           float64\n",
      "al.neg           float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_join.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b9a000a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['sentence_n', 'noun_n', 'words_n'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m col_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msource_title\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear_month\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl_TLD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m df_list \u001b[38;5;241m=\u001b[39m calculateStatsColList(df_join,col_list,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen\u001b[39m\u001b[38;5;124m\"\u001b[39m,display_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m df_list \u001b[38;5;241m=\u001b[39m calculateStatsColList(df_join,col_list,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlp\u001b[39m\u001b[38;5;124m\"\u001b[39m,display_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,display_stats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Article_LLM\\main_codebase\\article_scraping_lib.py:287\u001b[0m, in \u001b[0;36mcalculateStatsColList\u001b[1;34m(df, column_list, stat_type, display_df, display_stats, out_raw)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m column_list :\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stat_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlen\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 287\u001b[0m         df_app \u001b[38;5;241m=\u001b[39m calculateStatsLength(df,col,display_df)\n\u001b[0;32m    288\u001b[0m         df_list_out\u001b[38;5;241m.\u001b[39mappend(df_app)\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stat_type\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\OneDrive\\Desktop\\Article_LLM\\main_codebase\\article_scraping_lib.py:239\u001b[0m, in \u001b[0;36mcalculateStatsLength\u001b[1;34m(df, groupping, display_df)\u001b[0m\n\u001b[0;32m    237\u001b[0m rename_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_len\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchar_n\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentences\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_n\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoun_phrases\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoun_n\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwords\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwords_n\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m    238\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39mrename_dict)\n\u001b[1;32m--> 239\u001b[0m df_group \u001b[38;5;241m=\u001b[39m df[[groupping,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchar_n\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_n\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoun_n\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwords_n\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mgroupby(groupping)\u001b[38;5;241m.\u001b[39msum([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchar_n\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_n\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoun_n\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwords_n\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    240\u001b[0m df_count \u001b[38;5;241m=\u001b[39m df[groupping]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m.\u001b[39mto_frame(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    241\u001b[0m df_main \u001b[38;5;241m=\u001b[39m df_group\u001b[38;5;241m.\u001b[39mjoin(df_count, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m,on\u001b[38;5;241m=\u001b[39mgroupping)\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m],ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3767\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3766\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3767\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3769\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3770\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5877\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5874\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   5875\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 5877\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   5879\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   5880\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   5881\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:5941\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5938\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   5940\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 5941\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['sentence_n', 'noun_n', 'words_n'] not in index\""
     ]
    }
   ],
   "source": [
    "col_list = [\"category\",\"source_title\",\"year_month\",\"url_TLD\",\"year\"]\n",
    "df_list = calculateStatsColList(df_join,col_list,\"len\",display_df=True)\n",
    "df_list = calculateStatsColList(df_join,col_list,\"nlp\",display_df=True,display_stats=False) #,out_raw=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec600a34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
